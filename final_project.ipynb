{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPo6/r/7FcmUKeJTyRfMUz2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greymouse1/statistics/blob/main/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistics final project"
      ],
      "metadata": {
        "id": "RSrysQTg9oSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "from scipy import stats\n",
        "import numpy\n",
        "import itertools\n",
        "from tabulate import tabulate\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "from matplotlib import pyplot"
      ],
      "metadata": {
        "id": "PrlZ2q4zKbGy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imported functions"
      ],
      "metadata": {
        "id": "hFd-fTVMvc8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions in this block are provided by the course lecturers\n",
        "# Some of the code in other cells was also take from the course\n",
        "# Python examples. Courtesy of the course lecturers.\n",
        "\n",
        "def get_confidence_interval(data, confidence=0.95):\n",
        "    \"\"\" Determines the confidence interval for a given set of data,\n",
        "        assuming the population standard deviation is not known.\n",
        "\n",
        "    Args:  # 'arguments', or inputs to the function\n",
        "        data (single-column or list): The data\n",
        "        confidence (float): The confidence level on which to produce the interval.\n",
        "\n",
        "    Returns:\n",
        "        c_interval (tuple): The confidence interval on the given data (lower, upper).\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(data)  # determines the sample size\n",
        "    m = numpy.mean(data)  # obtains mean of the sample\n",
        "\n",
        "    se = stats.sem(data)  # obtains standard error of the sample\n",
        "\n",
        "    c_interval = stats.t.interval(confidence, n-1, m, se)  # determines the confidence interval\n",
        "    return c_interval  # which is of the form (lower bound, upper bound)\n",
        "\n",
        "def t_test(data_group1, data_group2, confidence=0.95):\n",
        "    alpha = 1-confidence\n",
        "\n",
        "    if stats.levene(data_group1, data_group2)[1]>alpha:\n",
        "        equal_variance = True\n",
        "    else:\n",
        "        equal_variance = False\n",
        "\n",
        "    t, p = stats.ttest_ind(data_group1, data_group2, equal_var = equal_variance)\n",
        "\n",
        "    reject_H0 = \"True\"\n",
        "    if p > alpha:\n",
        "        reject_H0 = \"False\"\n",
        "\n",
        "    return({'t': t, \"p\": p, \"Reject H0\": reject_H0})\n",
        "\n",
        "def ANOVA(dataset,independent,dependent,confidence = 0.95):\n",
        "    \"\"\" Calculates the ANOVA for a given dataset and prints an ANOVA table\n",
        "        and results of post hoc test if test was performed.\n",
        "\n",
        "    Args:  # 'arguments', or inputs to the function\n",
        "        dataset (pandas.DataFrame): The data\n",
        "        independent (string): The name of the independent column.\n",
        "        dependent (string): The name of the dependent column.\n",
        "        confidence (float): The desired confidence level for the ANOVA.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    groups = pandas.unique(dataset[independent])\n",
        "    k = len(groups)  # number of groups\n",
        "    n = len(dataset[dependent])  # number of dependent data points\n",
        "\n",
        "    # here we calculate the three degrees of freedom used in the ANOVA\n",
        "    DFbetween = k - 1\n",
        "    DFwithin = n - k\n",
        "    DFtotal = n - 1\n",
        "\n",
        "    # we use textbook notation:\n",
        "    # x_dd = sum over i and j x_ij\n",
        "    # x_id = sum over j x_ij\n",
        "    # x_dj = sum over i x_ij\n",
        "    # where i is the independent variable and j is the dependent variable\n",
        "\n",
        "    x_dd = sum(dataset[dependent])\n",
        "    CF = (x_dd**2)/n\n",
        "\n",
        "    SStotal = sum(x_ij**2 for x_ij in dataset[dependent]) - CF\n",
        "\n",
        "    SSbetween = 0\n",
        "    for i in groups:\n",
        "        group_data = dataset.loc[dataset[independent]==i]\n",
        "        n_i = len(group_data[dependent])\n",
        "        x_id = sum(group_data[dependent])\n",
        "        SSbetween += (x_id**2)/n_i\n",
        "\n",
        "    SSbetween = SSbetween - CF  # so^2 - s^2\n",
        "\n",
        "    SSwithin = SStotal - SSbetween\n",
        "\n",
        "    MSbetween = SSbetween/DFbetween\n",
        "    MSwithin = SSwithin/DFwithin\n",
        "\n",
        "    F = MSbetween/MSwithin\n",
        "    p = stats.f.sf(F, DFbetween, DFwithin)\n",
        "\n",
        "    print(tabulate([['Between', DFbetween, SSbetween, MSbetween, F],\n",
        "                    ['Within', DFwithin, SSwithin, MSwithin, ' '],\n",
        "                    ['Total', DFtotal, SStotal, ' ', ' ']],\n",
        "    headers=['Variation due to', 'DoF','Sum of squares','mean squares','F ratio']))\n",
        "    print('Significance (p value): '+str(p))\n",
        "    print('\\n')\n",
        "    alpha = 1-confidence\n",
        "    if p < alpha:\n",
        "        print(\"Reject null-hypothesis: There are statistical differences present.\")\n",
        "        print(pairwise_tukeyhsd(dataset[dependent], dataset[independent], alpha=alpha))\n",
        "    else:\n",
        "        print(\"Fail to reject the null-hypothesis: There are no statistical differences present at this level of significance.\")"
      ],
      "metadata": {
        "id": "JWx-qHbaLi_g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First question"
      ],
      "metadata": {
        "id": "x7UX5U1mvllz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3N0rXRSk9mIX"
      },
      "outputs": [],
      "source": [
        "# First step is to load the csv file\n",
        "\n",
        "# URL for csv\n",
        "data_url = \"https://raw.githubusercontent.com/greymouse1/statistics/refs/heads/main/PRO1_dataset.csv\"\n",
        "\n",
        "# Loaded file into data frame\n",
        "df = pandas.read_csv(data_url)\n",
        "\n",
        "# Calculate year mean in new column\n",
        "df[\"year_mean\"] = df.iloc[:,1:].mean(axis=1)\n",
        "\n",
        "# Since we need decades I will remove years from 1756-1759 (inclusive)\n",
        "# and year 2020. Decades will start at year ending with 0 and stop at\n",
        "# year ending with 9. Otherwise I can't avoid having one uncomplete decade\n",
        "# so this is for the sake of simplicity\n",
        "df.drop(df.index[0:4], inplace=True)\n",
        "df.drop(df[df[\"year\"]==2020].index, inplace=True)\n",
        "\n",
        "# Reset the index\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# Create column for decade\n",
        "# This will be first year of the decade but will include\n",
        "# the data for that year and all subsequent 9 years\n",
        "# For example, decade 1760 is decade with data for interval 1760-1769 (inc)\n",
        "df[\"decade\"] = (df[\"year\"]//10) * 10\n",
        "\n",
        "# Group values into new dataframe by year\n",
        "df_decade = df.groupby(\"decade\").agg({\"year_mean\": \"mean\"}).reset_index()\n",
        "\n",
        "# Rename column name for decade means\n",
        "df_decade.rename(columns={\"year_mean\":\"decade_mean\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# As a general assumption, we assume all years should have same means\n",
        "# Then we can look at all decades as one dataset or all years as one dataset\n",
        "\n",
        "# First let's use the index plot\n",
        "# Indices will be each decade\n",
        "\n",
        "fig = pyplot.Figure(figsize=(12, 4))\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "\n",
        "df_decade.reset_index().plot(x='index', y=\"decade_mean\", kind='scatter', ax=ax1)\n",
        "df.reset_index().plot(x='index', y=\"year_mean\", kind='scatter', ax=ax2)\n",
        "\n",
        "ax1.set(\n",
        "        xlabel='Index (decades)',\n",
        "        ylabel='$x$'\n",
        "    )\n",
        "ax2.set(\n",
        "        xlabel='Index (years)',\n",
        "        ylabel='$x$'\n",
        "    )\n",
        "fig\n",
        "\n",
        "# There seem to be some outliers in the top right corner for the last two decades"
      ],
      "metadata": {
        "id": "WM2Yyy1qjFNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see how histograms look like\n",
        "fig = pyplot.Figure(figsize=(12, 4))\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "\n",
        "df[\"year_mean\"].plot(kind=\"hist\", bins=10, alpha = 0.7, ax=ax1)\n",
        "df_decade[\"decade_mean\"].plot(kind=\"hist\", bins=5, alpha = 0.7, ax=ax2)\n",
        "\n",
        "ax1.set(\n",
        "        xlabel='$x$',\n",
        "        ylabel='Frequency'\n",
        "    )\n",
        "ax2.set(\n",
        "        xlabel='$x$',\n",
        "        ylabel='Frequency'\n",
        "    )\n",
        "fig\n",
        "\n",
        "# When looking at years, it may be that the data is normally distributed while for the decades we ahave only 26\n",
        "# data points and creating histogram will be inconclusive based on the number of bins we decide to choose"
      ],
      "metadata": {
        "id": "e35yahrmsPkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = pyplot.Figure(figsize=(12, 4))\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "\n",
        "df.boxplot(column=\"year_mean\", ax=ax1)\n",
        "df_decade.boxplot(column=\"decade_mean\", ax=ax2)\n",
        "\n",
        "ax1.set(\n",
        "        xlabel='Sample',\n",
        "        ylabel='$x$'\n",
        "    )\n",
        "\n",
        "ax2.set(\n",
        "        xlabel='Sample',\n",
        "        ylabel='$x$'\n",
        "    )\n",
        "fig\n",
        "\n",
        "# He we compare box plot for all years and for all decades\n",
        "# There seem to be some decades which stand out of the mean for all the decades"
      ],
      "metadata": {
        "id": "ME67TSFFubFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To check for years which could stand out for each individual decade, there has to be a box plot for\n",
        "# each of the decades\n",
        "# Create a figure with a specified size\n",
        "fig, ax = pyplot.subplots(figsize=(12, 6))  # Use the appropriate size here\n",
        "\n",
        "# Plot the boxplot for temperatures by decade\n",
        "df.boxplot(column='year_mean', by='decade', patch_artist=True, ax=ax)\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_title('Yearly Temperature Distribution by Decade')\n",
        "pyplot.suptitle('')  # Remove the default title generated by `boxplot()`\n",
        "ax.set_xlabel('Decade')\n",
        "ax.set_ylabel('Temperature')\n",
        "\n",
        "# Show the plot\n",
        "pyplot.show()\n",
        "\n",
        "fig.savefig('temperature_distribution.png')\n",
        "\n"
      ],
      "metadata": {
        "id": "p7HqzLAhvHvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second question\n"
      ],
      "metadata": {
        "id": "pU8PfDT4vsuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data now has to be grouped by century\n",
        "# For this I use original dataset\n",
        "df[\"century\"] = (df[\"year\"]//100) + 1\n",
        "\n",
        "# Separate by century\n",
        "df_19th = df[df[\"century\"] == 19][\"year_mean\"].reset_index(drop=True)\n",
        "df_20th = df[df[\"century\"] == 20][\"year_mean\"].reset_index(drop=True)\n",
        "\n",
        "# Group values into new dataframe by century\n",
        "df_century = pandas.concat({\"19th\": df_19th, \"20th\": df_20th}, axis=1)\n",
        "\n",
        "# Create a figure with a specified size\n",
        "specific_centuries = [19, 20]\n",
        "filtered_df = df[df[\"century\"].isin(specific_centuries)]\n",
        "fig, ax = pyplot.subplots(figsize=(6, 3))  # Use the appropriate size here\n",
        "\n",
        "# Plot the boxplot for temperatures by decade\n",
        "filtered_df.boxplot(column='year_mean', by='century', patch_artist=True, ax=ax)\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_title('Yearly Temperature Distribution by century')\n",
        "pyplot.suptitle('')  # Remove the default title generated by `boxplot()`\n",
        "ax.set_xlabel('Century')\n",
        "ax.set_ylabel('Temperature')\n",
        "\n",
        "# Show the plot\n",
        "pyplot.show()\n",
        "fig.savefig('temperature_distribution_centuries.png')"
      ],
      "metadata": {
        "id": "NIRdOf7Yv0B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get group statistics\n",
        "print(df_century.describe())"
      ],
      "metadata": {
        "id": "OV88eYPR4D2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the confidence intervals\n",
        "print(\"Century 19\", get_confidence_interval(df_century[\"19th\"], confidence=0.95))\n",
        "print(\"Century 20:\", get_confidence_interval(df_century[\"20th\"], confidence=0.95))"
      ],
      "metadata": {
        "id": "PcRxRdN65koT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t-test\n",
        "t_test(df_century[\"19th\"], df_century[\"20th\"], confidence=0.95)"
      ],
      "metadata": {
        "id": "DFceZk7S7vaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Third question"
      ],
      "metadata": {
        "id": "r9okQ5eJ978v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new df for the last five centuries\n",
        "\n",
        "decade1970 = df[df[\"decade\"] == 1970][\"year_mean\"].reset_index(drop=True)\n",
        "decade1980 = df[df[\"decade\"] == 1980][\"year_mean\"].reset_index(drop=True)\n",
        "decade1990 = df[df[\"decade\"] == 1990][\"year_mean\"].reset_index(drop=True)\n",
        "decade2000 = df[df[\"decade\"] == 2000][\"year_mean\"].reset_index(drop=True)\n",
        "decade2010 = df[df[\"decade\"] == 2010][\"year_mean\"].reset_index(drop=True)\n",
        "df_five_decades = pandas.concat({\"1970\": decade1970, \"1980\": decade1980, \"1990\": decade1990, \"2000\": decade2000, \"2010\": decade2010}, axis=1)\n",
        "\n",
        "# Shapiro-Wilk test\n",
        "for decade in df_five_decades.columns:\n",
        "    print(f\"Results of the Shapiro-Wilk for decade {decade}:\", stats.shapiro(df_five_decades[decade]))"
      ],
      "metadata": {
        "id": "T-9S700Q-AeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = pyplot.Figure(figsize=(6, 4))\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "df_five_decades.reset_index().plot(x='index', y=\"2010\", kind='scatter', ax=ax1)\n",
        "\n",
        "\n",
        "ax1.set(\n",
        "        xlabel='Index (decades)',\n",
        "        ylabel='$x$'\n",
        "    )\n",
        "fig\n",
        "fig.savefig('five_decades.png')"
      ],
      "metadata": {
        "id": "S8hFLxmeHBIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leven test\n",
        "for decade1, decade2 in itertools.combinations(df_five_decades.columns,2):\n",
        "    print(decade1, decade2, stats.levene(df_five_decades[decade1], df_five_decades[decade2]))"
      ],
      "metadata": {
        "id": "FyMzjbTjNK2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Welch ANOVA for unequal variances\n",
        "f_stat, p_value = stats.f_oneway(\n",
        "    df_five_decades['1970'],\n",
        "    df_five_decades['1980'],\n",
        "    df_five_decades['1990'],\n",
        "    df_five_decades['2000'],\n",
        "    df_five_decades['2010']\n",
        ")\n",
        "print(f\"F-statistic: {f_stat}\")\n",
        "print(f\"p-value: {p_value}\")"
      ],
      "metadata": {
        "id": "BfwwndOaQc0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Posthoc\n",
        "df_long = df_five_decades.melt(var_name='decade', value_name='temperature')\n",
        "\n",
        "df_long.head()\n",
        "\n",
        "!pip install pingouin\n",
        "import pingouin as pg\n",
        "\n",
        "# Perform the Games-Howell post-hoc test\n",
        "posthoc = pg.pairwise_gameshowell(dv='temperature', between='decade', data=df_long)\n",
        "\n",
        "# Display the results\n",
        "print(posthoc)"
      ],
      "metadata": {
        "id": "tcQvfvYITsXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fourth question"
      ],
      "metadata": {
        "id": "a92wvuZK7-fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data has to be remodelled so it has summer and winter means\n",
        "# For this I use starting raw data\n",
        "# Loaded file into data frame\n",
        "df_summer_winter = pandas.read_csv(data_url)\n",
        "\n",
        "# Create an empty DataFrame to store the results\n",
        "summary_df = pandas.DataFrame(columns=[\"year\", \"mean_summer\", \"mean_winter\"])\n",
        "\n",
        "# Loop through each unique year\n",
        "for selected_year in df_summer_winter[\"year\"].unique():\n",
        "    # Select the row for the specific year\n",
        "    selected_row = df_summer_winter[df_summer_winter[\"year\"] == selected_year]\n",
        "\n",
        "    # Calculate the average for the winter months\n",
        "    # December of the current year and January, February of the next year\n",
        "    if selected_year + 1 in df_summer_winter[\"year\"].values:\n",
        "        # Calculate the average for the summer months (June, July, August)\n",
        "        summer_avg = selected_row[[\"jun\", \"jul\", \"aug\"]].mean(axis=1).values[0]\n",
        "\n",
        "        next_year_row = df_summer_winter[df_summer_winter[\"year\"] == selected_year + 1]\n",
        "        winter_avg = (selected_row[\"dec\"].values[0] + next_year_row[\"jan\"].values[0] + next_year_row[\"feb\"].values[0]) / 3\n",
        "\n",
        "    else:\n",
        "        break  # Handle case if no next year (e.g., for the last year in dataset)\n",
        "\n",
        "    # Append the results to the summary DataFrame\n",
        "    summary_df = pandas.concat([summary_df, pandas.DataFrame({\n",
        "    \"year\": [selected_year],\n",
        "    \"mean_summer\": [summer_avg],\n",
        "    \"mean_winter\": [winter_avg]\n",
        "    })], ignore_index=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r65cWDh08Cbh",
        "outputId": "5e9e5219-f5e8-4726-b20b-72cda68fc119"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-1f0167c531e4>:27: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  summary_df = pandas.concat([summary_df, pandas.DataFrame({\n"
          ]
        }
      ]
    }
  ]
}